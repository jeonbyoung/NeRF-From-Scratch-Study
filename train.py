import os
import numpy as np
import torch
import matplotlib.pyplot as plt
from tqdm import tqdm

from get_rays import get_ray
from get_rgb import get_rgb
from get_samples import get_samples
from data_loader import load_full_data
from set_device import set_device
from volume_rendering import volume_rendering

def mse2pnsr(mse):
      return -10 * torch.log10(mse)

# Í≤ÄÏ¶ùÏö© img 1Ïû•(testÏùò 0Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄÎ°ú) Î†åÎçîÎßÅ Ìï®Ïàò
@torch.no_grad() # ÌïôÏäµ ÏïÑÎãàÎãà, grad ÌïòÏßÄ ÎßêÎùºÎäî ÌëúÏãú
def rendering_one_img_for_test(model, idx=0, device = None, target='lego'):
      width, height = 800, 800
      rays_d, rays_o, img_file_path = get_ray(category='test', target=target, i=idx)

      rays_o = torch.from_numpy(rays_o.reshape(-1,3).copy()).float().to(device)
      rays_d = torch.from_numpy(rays_d.reshape(-1,3).copy()).float().to(device)

      true_img = get_rgb(img_file_path)

      # chunkingÏúºÎ°ú Î©îÎ™®Î¶¨ ÌÑ∞ÏßÄÎäî Í±∞ Î∞©ÏßÄ
      chunk_size = 1024
      all_rgb = []

      for i in range(0, rays_o.shape[0], chunk_size):
            batch_o = rays_o[i : i+chunk_size]
            batch_d = rays_d[i : i+chunk_size]
            
            # testÎãàÍπå Í∑∏ÎÉ• 64Í∞ú Ìè¨Ïù∏Ìä∏Î°ú ÏßÄÏ†ï
            pts, t_vals = get_samples(batch_d, batch_o, num_of_samples = 128, mode='test')

            pts_flat = pts.reshape(-1,3)
            dirs_expanded = batch_d[:,None,:].expand_as(pts)
            dirs_flat = dirs_expanded.reshape(-1,3)

            raw_rgb, raw_sigma = model(pts_flat, dirs_flat)

            rgb_for_vr = raw_rgb.reshape(batch_o.shape[0],128,3)
            sigma_for_vr = raw_sigma.reshape(batch_o.shape[0],128)

            rgb_chunk = volume_rendering(rgb_for_vr, sigma_for_vr, t_vals)

            all_rgb.append(rgb_chunk.cpu())

      pred_img= torch.cat(all_rgb, dim=0).reshape(height, width, 3).numpy()

      pred_img = np.clip(pred_img, 0 ,1)

      return pred_img, true_img



def train(model=None, optimizer=None, target = 'lego'):
      device = set_device()

      model = model.to(device)
      scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1**(1/200000))

      num_img = 100
      num_of_pts_per_ray = 128

      merged_ray_o, merged_ray_d, merged_rgb = load_full_data(num_img, target)

      try:
            total_pixels = len(merged_rgb)
            num_imgs = 100 # Î°úÎìúÌïú Ïù¥ÎØ∏ÏßÄ Ïàò (ÏÑ§Ï†ïÏóê ÎßûÍ≤å Î≥ÄÍ≤Ω)
            pixels_per_img = total_pixels // num_imgs
            
            # Ï†ïÏÇ¨Í∞ÅÌòï Ìïú Î≥ÄÏùò Í∏∏Ïù¥ Ïó≠ÏÇ∞
            H_crop = int(np.sqrt(pixels_per_img))
            W_crop = H_crop
            
            print(f"Calculated Crop Size: {H_crop}x{W_crop}")

            # 2. Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄ Î≥µÍµ¨ ÏãúÎèÑ
            test_img_flat = merged_rgb[:pixels_per_img]
            test_img = test_img_flat.reshape(H_crop, W_crop, 3).cpu().numpy()

            # 3. Í∑∏Î¶º Í∑∏Î¶¨Í∏∞
            plt.figure(figsize=(5,5))
            plt.imshow(test_img)
            plt.title(f"Check: Is this a Lego? (Loss: 0.3)")
            plt.axis('off')
            plt.show()
            plt.close()

            # ÏÇ¨Ïö©Ïûê ÌôïÏù∏Ïö© (Ïû†Ïãú Î©àÏ∂§)
            input("üõë Ïù¥ÎØ∏ÏßÄÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî! Î†àÍ≥†Í∞Ä Î≥¥Ïù¥Î©¥ ÏóîÌÑ∞, ÎÖ∏Ïù¥Ï¶àÎ©¥ Ï§ëÎã®.")

      except Exception as e:
            print(f"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ ÌôïÏù∏ Ïã§Ìå®: {e}")

      # Ïù¥Ï†ú ÌïôÏäµ ÏãúÏûë
      # epochÎèÑ ÏÑ§Ï†ïÌïòÍ≥†, sampleÏùÑ Î™á Í∞ú Ïì∏ ÏßÄÎèÑ Í≤∞Ï†ïÌïòÎ©¥ ÎêúÎã§.
      epoch = 200000
      num_of_rays = 512
      start_epoch = 0

      # ÎÖ∏Ìä∏Î∂Å Î∞úÏó¥Ïù¥ Ïã¨Ìï¥ÏÑú Ïû†Íπê Î©àÏ∑ÑÎã§. ÏïÑÎûòÎäî Í∑∏ÎèôÏïà ÌïôÏäµÌïú Í±∞ Ï†ÄÏû•Ìïú Í±∏ Í∞ÄÏßÄÍ≥† Ïù¥Ïñ¥ÎÇòÍ∞ÄÎäî ÏΩîÎìúÎã§.
      # ÏïÑÎûò resume_pathÎäî ÏßÅÏ†ë ÏçºÎã§. ÎÇòÏ§ëÏóê Ï§ëÎã® Ìè¨Ïù∏Ìä∏Í∞Ä Î∞îÎÄåÎ©¥ Î≥ÄÍ≤ΩÌï¥ÏÑú ÌïòÎ©¥ Îê®.
      resume_path = 'NeRF_weights/NeRF_weights_n.pth'

      if os.path.exists(resume_path):
            print(f"Resuming training from {resume_path}")
            
            checkpoint = torch.load(resume_path, map_location=device)
            model.load_state_dict(checkpoint)

            try:
                  loaded_epoch = int(resume_path.split('_')[-1].replace('.pth',''))
                  start_epoch = loaded_epoch + 1
                  print(f"Train restarted from {start_epoch}!")

            except:
                  print("Cannot read the epoch_num. Restart from 0 epoch.")
                  start_epoch = 0

      else:
            print('Train start from scratch! No check point found')

      pbar = tqdm(range(start_epoch,epoch),ncols=100)

      for i in pbar:
            idx = np.random.choice(len(merged_ray_d),num_of_rays)

            batch_o = merged_ray_o[idx].to(device)
            batch_d = merged_ray_d[idx].to(device)
            batch_rgb = merged_rgb[idx].to(device)

            pts, pts_dist_info = get_samples(batch_d, batch_o, mode='train', num_of_samples=num_of_pts_per_ray)


            # Ïó¨Í∏∞Î∂ÄÌÑ∞ Ï°∞Í∏à Ïñ¥Î†µÎã§...
            # Non-Lambertian EffectÏóê ÎåÄÌïú ÎÇ¥Ïö©ÏùÑ Îã¥ÏïÑÏÑú ptsÎ•º Î≥ÄÌòïÌï¥Ï§òÏïºÌïúÎã§.
            # Non-Lambertian EffectÎûÄ Î≥¥Îäî Í∞ÅÎèÑÏóê Îî∞ÎùºÏÑú Ìï¥Îãπ Î¨ºÏ≤¥Ïùò ÏÉâÏù¥ Î≥ÄÌïúÎã§Îäî ÎÇ¥Ïö©Ïù¥Îã§.
            # ÏßÄÍ∏à ÎΩëÏïÑÎÇ∏ ptsÎäî Í∑∏ÎÉ• Í≥µÍ∞Ñ ÏÉÅÏùò 'ÏúÑÏπò'Î•º ÎÇòÌÉÄÎÇ∏ Í∞íÏù¥Îã§. Ï¶â, Ïù¥ Ï†êÏùÑ Ïñ¥ÎîîÏÑú Î∞îÎùºÎ≥¥Í≥† ÏûàÎäî ÏßÄÏóê ÎåÄÌïú Í≤ÉÎèÑ ÎÑ£Ïñ¥Ï§òÏïºÌïúÎã§Îäî Í≤ÉÏù¥Îã§.
            # Í∑∏ Í∞íÏù¥ Í≤∞Íµ≠Ïóî modelÏùò inputÏù¥ ÎêòÎäî, [ÏúÑÏπò | Î∞îÎùºÎ≥¥Îäî Í∞ÅÎèÑÏù∏, view] ÌòïÌÉúÎ•º Íµ¨ÌòÑÌïòÎäî Í≤ÉÏù¥Îã§.
            
            # Í∑∏Î¶¨Í≥† batch_dÎäî Í∑∏ÎÉ• Î≥∏Ïù∏Ïùò Î∞©Ìñ•Îßå ÎÇòÌÉÄÎÇ¥Í≥† ÏûàÎäî 1024 * 3Ïùò ÌòïÌÉúÎã§. Ïù¥Í±∏ Ïö∞ÏÑ† ptsÏôÄ Î™®ÏñëÏùÑ ÎßûÏ∂∞Ï§òÏïº ÌïúÎã§.
            direction_expanded = batch_d[:,None,:].expand_as(pts)

            # Í∑∏Îüº Î∞©Ìñ• ÌñâÎ†¨Í≥º ptsÎäî ÌòÑÏû¨, 1024 * 64 * 3(x,y,z) ÌòïÌÉúÏù¥Îã§. Ï†Ä ÏïûÏóê 1024 * 64Ïùò Ï†êÎì§ÏùÑ Ìï©Ï≥êÏÑú dim = 2Î°ú ÎßåÎì§Ïñ¥Ï§òÏïºÌïúÎã§.
            pts_for_model = pts.reshape(-1,3)

            dir_for_model = direction_expanded.reshape(-1,3)

            # Ïù¥Ï†ú (pts_for_model, dir_for_model)Ïù¥ÎùºÎäî ÌéòÏñ¥Í∞Ä ÎßåÎì§Ïñ¥Ï°åÍ≥†, Ïù¥ Í∞íÏù¥ modelÏùò inputÏúºÎ°úÏÑú Îì§Ïñ¥Í∞ÄÏßÑÎã§.
            from_model_rgb, from_model_sigma = model.forward(pts_for_model,dir_for_model)


            # Ïù¥Î†áÍ≤å ModelÏùÑ Í±∞ÏπòÍ≥† Ïò® pred_rgb, pred_sigmaÎ•º Í∞ÄÏßÄÍ≥†, volume_renderingÏùÑ Ìï¥ÏïºÌïúÎã§. Í∑∏ Í≤∞Í≥ºÎ•º ÌÜµÌï¥ ÎÇòÏò® colorÎ•º Í∞ÄÏßÄÍ≥† Ïã§Ï†ú Í∞íÍ≥º ÎπÑÍµêÌï† Í≤ÉÏù¥Îãà.
            # Í∑∏ÎûòÏÑú Ïö∞ÏÑ† volume renderingÏùÑ ÏúÑÌï¥, ÏñòÍ∞Ä Ïñ¥Îäê viewÏóêÏÑú ÎÇòÏò® Í±¥ÏßÄ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌï¥, Îã§Ïãú ray Îã®ÏúÑÎ°ú Î¨∂ÎäîÎã§.
            rgb_for_vr = from_model_rgb.reshape(num_of_rays, num_of_pts_per_ray, 3) # Ïù¥ÎïåÏùò 3ÏùÄ rgb Í∞í
            sigma_for_vr = from_model_sigma.reshape(num_of_rays,num_of_pts_per_ray) # densityÏóê Ìï¥ÎãπÌïòÎäî sigmaÎäî Ïä§ÏπºÎùºÎã§.

            # Ïù¥Ï†ú volume renderingÏùÑ Ìï† Ï∞®Î°ÄÎã§.
            pred_rgb = volume_rendering(rgb_for_vr,sigma_for_vr,pts_dist_info)


            # lossÎèÑ Íµ¨ÌïòÏûê. using MSE
            loss = torch.mean((pred_rgb - batch_rgb)**2)
            
            if(i%10==0):
                  with torch.no_grad():
                        current_psnr = mse2pnsr(loss).item()
                  pbar.set_postfix({'Epoch': i,'Loss': loss.item() ,'PSNR': f'{current_psnr:.2f}'})

            # Ïù¥Ï†Ñ gradientÍ∞í Ï¥àÍ∏∞Ìôî
            optimizer.zero_grad()

            loss.backward()
            # Ïó¨Í∏∞ÏÑú ÏùòÎ¨∏Ï†êÏù¥ Îì§ÏóàÎã§.
            # lossÎ•º optimizerÍ∞Ä Ïù¥Î†áÍ≤å ÎêòÎ©¥ Ïñ¥Ï∞å ÏïÑÎäîÍ∞Ä?
            # ÏòÅÌäπÌïú optimizerÎãòÏùÄ ÏïåÏïÑÏÑú ÏïàÎã§Í≥† ÌïòÏã†Îã§.
            # Ï†ïÌôïÌûàÎäî lossÍ∞Ä torchÏïàÏóêÏÑú w.gradÎùºÎäî Î≥ÄÏàòÏóê Ï†ÄÏû•ÎêúÎã§Í≥† ÌïúÎã§.

            # optimizerÍ∞Ä Ïù¥Í≤ÉÏùÑ ÏùΩÏñ¥ÏÑú Ïò§Î•òÎ•º Î∞òÏòÅÌï¥Ï§ÄÎã§.
            optimizer.step()
            scheduler.step()

            # OOM Î∞©ÏßÄ
            del pred_rgb, batch_rgb, pts, pts_for_model, from_model_rgb, from_model_sigma
            if i%100 == 0:
                  torch.cuda.empty_cache()


            # ÏßÑÏßúÏôÄ ÎπÑÍµê and Í∞ÄÏ§ëÏπò Ï†ÄÏû•
            if i%2000 == 0 and i >0:
                  # PSNRÍ≥º ÏßÑÏßú Ïù¥ÎØ∏ÏßÄÏôÄÏùò ÎπÑÍµêÎ•º ÌÜµÌï¥, ÏßÅÏ†ë ÏñºÎßàÎÇò ÏÑ±Ïû•ÌñàÎÇò Î≥¥Í∏∞
                  psnr_val = mse2pnsr(loss).item()

                  model.eval()
                  with torch.no_grad():
                        pred_img, true_img = rendering_one_img_for_test(model, idx=0, device = device, target=target)
                  model.train()

                  current_lr = optimizer.param_groups[0]['lr']
                  pbar.set_postfix({'Loss':f'{loss.item():.4f}', 
                                    'PSNR' : f'{psnr_val:.2f}',
                                    'LR': f'{current_lr:.6f}'
                              })

                  combined_img = np.hstack((pred_img, true_img))

                  save_dir = 'test_img'
                  if not os.path.exists(save_dir):
                        os.makedirs(save_dir)

                  plt.figure(figsize=(10,5))

                  plt.imshow(combined_img)
                  plt.text(10,700+60, f"Epoch: {i}\nPSNR: {psnr_val:.2f} dB",
                           color = 'yellow', fontsize=12, fontweight = 'bold',
                           bbox = dict(facecolor='black', alpha= 0.5))
                  
                  plt.text(10, 30, 'Prediction', color = 'black', fontweight = 'bold')
                  plt.text(800+10, 30, "Truth", color = 'black', fontweight ='bold')

                  plt.axis('off')


                  save_path = f"test_img/test_{i}_epoch.png"
                  plt.savefig(save_path, bbox_inches='tight', pad_inches= 0)
                  plt.close()


                  # Í∞ÄÏ§ëÏπò Ï†ÄÏû•
                  save_dir = 'NeRF_weights'
        
                  if not os.path.exists(save_dir):
                        os.makedirs(save_dir)

                  file_path = os.path.join(save_dir, f"NeRF_weights_{i}.pth")

                  torch.save(model.state_dict(), file_path)



        

